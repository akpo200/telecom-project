# Syst√®me RAG pour Entreprise de T√©l√©communication
## Framework et outils utilis√©s

### Framework RAG et LLM
langchain>=0.1.0
langchain-community>=0.0.10

# Mod√®le d'embeddings
sentence-transformers>=2.2.0

# Base vectorielle
faiss-cpu>=1.7.0

# Chargement de documents
pypdf>=3.0.0
python-docx>=1.0.0

# Interface utilisateur
streamlit>=1.29.0

# Utilitaires
python-dotenv>=1.0.0

# Ollama (client Python)
ollama>=0.1.0

# Autres d√©pendances
numpy>=1.24.0


## STRUCTURE DU PROJET

Ce document pr√©sente un projet complet de mise en place d'un syst√®me RAG (Retrieval-Augmented Generation) destin√© aux entreprises de t√©l√©communication.

**Le projet est structur√© en deux parties principales :**

### **PARTIE 1 ‚Äì Introduction et cadrage du projet**
- Contexte et probl√©matique
- Objectifs du projet
- Choix technologiques et justifications
- Architecture conceptuelle globale

### **PARTIE 2 ‚Äì Mise en place technique et h√©bergement** üîÑ
- Environnement de travail
- Configuration des mod√®les
- Constitution de la base de connaissances
- Impl√©mentation du pipeline RAG
- H√©bergement et d√©ploiement
- Interface utilisateur
- Limites et am√©liorations

---

## PARTIE 1 ‚Äì INTRODUCTION ET CADRAGE DU PROJET

### 1. Contexte et probl√©matique dans les entreprises de t√©l√©communication

#### 1.1. Le secteur des t√©l√©communications au S√©n√©gal et en Afrique de l'Ouest

Le march√© des t√©l√©communications en Afrique de l'Ouest, et particuli√®rement au S√©n√©gal, conna√Æt une croissance soutenue depuis deux d√©cennies. Des op√©rateurs majeurs tels qu'**Orange**, **Expresso**, **Free** et d'autres acteurs r√©gionaux se partagent un march√© dynamique caract√©ris√© par :

- Une **forte concurrence** sur les offres mobiles, internet et services entreprises
- Une **diversification rapide** des produits (forfaits pr√©pay√©s, postpay√©s, data, services financiers mobiles)
- Des **√©volutions r√©glementaires fr√©quentes** impos√©es par l'ARTP (Autorit√© de R√©gulation des T√©l√©communications et des Postes)
- Une **client√®le exigeante** en termes de qualit√© de service et de r√©activit√©

#### 1.2. Les d√©fis de la gestion de la connaissance interne

Dans ce contexte hautement comp√©titif, les entreprises de t√©l√©communication font face √† une probl√©matique critique : **la fragmentation et l'inaccessibilit√© de l'information interne**.

**Les √©quipes commerciales et support client** doivent quotidiennement r√©pondre √† des questions complexes portant sur :

- Les **caract√©ristiques techniques** des offres (d√©bits, couverture r√©seau, compatibilit√©)
- Les **conditions contractuelles** (dur√©es d'engagement, p√©nalit√©s, clauses de r√©siliation)
- Les **proc√©dures internes** (activation de services, traitement des r√©clamations, escalade)
- Les **SLA (Service Level Agreements)** applicables aux clients entreprises
- Les **promotions en cours** et leurs conditions d'√©ligibilit√©
- Les **politiques tarifaires** et grilles de prix

**Or, cette information est actuellement dispers√©e dans :**

- Des documents PDF stock√©s sur des serveurs partag√©s
- Des bases de donn√©es internes non interconnect√©es
- Des emails et communications internes
- Des syst√®mes de gestion documentaire (GED) peu ergonomiques
- La m√©moire institutionnelle de collaborateurs exp√©riment√©s

**Les cons√©quences de cette fragmentation sont multiples :**

1. **Perte de temps** : Les agents passent en moyenne 20 √† 30% de leur temps √† chercher l'information
2. **Incoh√©rence des r√©ponses** : Diff√©rents agents peuvent fournir des informations contradictoires
3. **Risques juridiques** : Des erreurs sur les conditions contractuelles peuvent engager la responsabilit√© de l'entreprise
4. **Insatisfaction client** : Les d√©lais de r√©ponse s'allongent, impactant l'exp√©rience client
5. **Turnover et formation** : L'int√©gration des nouveaux collaborateurs est ralentie par la difficult√© d'acc√®s √† la connaissance

#### 1.3. Le besoin d'une solution intelligente et centralis√©e

Face √† ces d√©fis, les entreprises de t√©l√©communication ont besoin d'une solution qui permette de :

- **Centraliser** l'ensemble de la documentation interne dans un syst√®me unique
- **Interroger** cette base de connaissances en langage naturel, sans requ√™tes techniques
- **Obtenir des r√©ponses pr√©cises**, contextualis√©es et **justifi√©es par les sources**
- **Garantir la confidentialit√©** des donn√©es sensibles de l'entreprise
- **Maintenir la solution √† jour** facilement, au rythme des √©volutions de l'offre

C'est pr√©cis√©ment l'objectif du syst√®me RAG (Retrieval-Augmented Generation) que nous proposons de d√©velopper dans le cadre de ce projet.

---

### 2. Objectifs du projet

Ce projet vise √† concevoir et d√©ployer un **syst√®me RAG op√©rationnel** r√©pondant aux besoins sp√©cifiques d'une entreprise de t√©l√©communication. Les objectifs sont structur√©s en trois niveaux :

#### 2.1. Objectifs fonctionnels

**OF1 ‚Äì Centralisation de la connaissance**
- Constituer une base de connaissances unifi√©e regroupant l'ensemble de la documentation interne pertinente (offres commerciales, proc√©dures techniques, conditions g√©n√©rales, SLA, FAQ internes)
- Permettre l'ingestion de documents dans diff√©rents formats (PDF, Word, texte, HTML)

**OF2 ‚Äì Interrogation en langage naturel**
- Permettre aux utilisateurs (√©quipes commerciales, support client, managers) de poser des questions en fran√ßais, dans un langage naturel et conversationnel
- Exemple : *"Quelles sont les conditions de r√©siliation anticip√©e pour un forfait entreprise Orange Pro 100 Go ?"*

**OF3 ‚Äì G√©n√©ration de r√©ponses contextualis√©es**
- Fournir des r√©ponses pr√©cises, synth√©tiques et directement exploitables
- Citer syst√©matiquement les sources documentaires utilis√©es pour g√©n√©rer la r√©ponse
- Permettre √† l'utilisateur de v√©rifier l'information en consultant le document source

**OF4 ‚Äì Maintien de la coh√©rence et de la fiabilit√©**
- Garantir que les r√©ponses sont bas√©es uniquement sur les documents internes (pas d'hallucinations)
- Assurer la tra√ßabilit√© des informations fournies

#### 2.2. Objectifs techniques

**OT1 ‚Äì Architecture RAG robuste**
- Impl√©menter un pipeline RAG complet : ingestion, vectorisation, indexation, recherche s√©mantique, g√©n√©ration augment√©e
- Utiliser des embeddings de qualit√© pour capturer le sens des documents

**OT2 ‚Äì Flexibilit√© des mod√®les de langage**
- Permettre l'utilisation de **mod√®les locaux** via Ollama (pour la confidentialit√© et le contr√¥le)
- Permettre l'utilisation de **mod√®les via API** (OpenAI, Mistral AI) pour des performances optimales
- Faciliter le changement de mod√®le selon les besoins et contraintes

**OT3 ‚Äì D√©ploiement adapt√© au contexte t√©l√©com**
- Proposer une solution d√©ployable **on-premise** (sur les serveurs de l'entreprise) pour garantir la confidentialit√©
- Proposer une alternative **cloud hybride** pour les entreprises ayant une politique cloud
- Assurer la scalabilit√© de la solution pour g√©rer des volumes documentaires importants

**OT4 ‚Äì Interface utilisateur accessible**
- D√©velopper une interface web simple et intuitive (Streamlit)
- Permettre un acc√®s √† distance s√©curis√© pour les √©quipes terrain

#### 2.3. Objectifs p√©dagogiques et d√©monstratifs

**OP1 ‚Äì Ma√Ætrise des technologies RAG**
- D√©montrer la compr√©hension approfondie des concepts de RAG
- Illustrer l'utilisation de LangChain pour orchestrer les composants du syst√®me

**OP2 ‚Äì Compr√©hension des enjeux d'h√©bergement**
- Montrer la ma√Ætrise des diff√©rences entre d√©ploiement on-premise et cloud
- Justifier les choix techniques en fonction des contraintes de s√©curit√© et de performance

**OP3 ‚Äì Alignement avec les besoins m√©tier**
- Proposer une solution r√©aliste, adapt√©e aux contraintes d'une entreprise de t√©l√©communication
- Ne pas sur-promettre techniquement, rester dans le cadre d'un MVP (Minimum Viable Product) r√©aliste

---

### 3. Choix technologiques et justification

Le syst√®me RAG propos√© repose sur un ensemble de technologies open-source et de mod√®les de langage s√©lectionn√©s pour leur pertinence, leur accessibilit√© et leur ad√©quation avec les contraintes du projet.

#### 3.1. RAG (Retrieval-Augmented Generation) : le c≈ìur du syst√®me

**Qu'est-ce que le RAG ?**

Le RAG est une approche qui combine :
- La **recherche d'information** (Retrieval) dans une base de connaissances
- La **g√©n√©ration de texte** (Generation) par un mod√®le de langage (LLM)

**Pourquoi le RAG pour ce projet ?**

Les mod√®les de langage (LLM) classiques, m√™me tr√®s performants, pr√©sentent deux limites majeures pour notre cas d'usage :

1. **Connaissance limit√©e** : Ils ne connaissent pas les informations internes sp√©cifiques √† l'entreprise (offres, proc√©dures, SLA)
2. **Hallucinations** : Ils peuvent g√©n√©rer des r√©ponses plausibles mais factuellement incorrectes

Le RAG r√©sout ces probl√®mes en :
- **Recherchant d'abord** les passages pertinents dans la base documentaire interne
- **Fournissant ces passages au LLM** comme contexte pour g√©n√©rer une r√©ponse
- **Garantissant** que la r√©ponse est ancr√©e dans les documents r√©els de l'entreprise

**Avantages du RAG pour les t√©l√©coms :**

- ‚úÖ **Fiabilit√©** : Les r√©ponses sont bas√©es sur des sources v√©rifiables
- ‚úÖ **Actualisation facile** : Il suffit d'ajouter/modifier des documents, pas besoin de r√©entra√Æner un mod√®le
- ‚úÖ **Tra√ßabilit√©** : Chaque r√©ponse peut √™tre justifi√©e par ses sources
- ‚úÖ **Confidentialit√©** : Les donn√©es restent dans le syst√®me de l'entreprise

#### 3.2. LangChain : l'orchestrateur du pipeline RAG

**Qu'est-ce que LangChain ?**

LangChain est un framework Python open-source con√ßu pour d√©velopper des applications bas√©es sur des mod√®les de langage. Il fournit des abstractions et des composants r√©utilisables pour :

- Charger et d√©couper des documents (Document Loaders, Text Splitters)
- Cr√©er des embeddings et des bases vectorielles (Embeddings, Vector Stores)
- G√©rer les interactions avec les LLM (LLM Wrappers, Chains)
- Construire des pipelines RAG complets (Retrieval QA Chains)

**Pourquoi LangChain ?**

1. **Modularit√©** : Permet de changer facilement de mod√®le, de base vectorielle ou de strat√©gie de d√©coupage
2. **Compatibilit√©** : Supporte de nombreux LLM (OpenAI, Mistral, Ollama, etc.) et bases vectorielles (FAISS, Chroma, Pinecone)
3. **Productivit√©** : √âvite de r√©inventer la roue, acc√©l√®re le d√©veloppement
4. **Communaut√© active** : Documentation riche, nombreux exemples, mises √† jour fr√©quentes
5. **Alignement p√©dagogique** : Outil de r√©f√©rence pour apprendre et ma√Ætriser les concepts RAG

**Utilisation dans le projet :**

LangChain sera utilis√© pour :
- Charger les documents internes (PDF, DOCX, TXT)
- D√©couper les documents en chunks (morceaux) de taille optimale
- G√©n√©rer les embeddings vectoriels
- Stocker les vecteurs dans une base vectorielle (FAISS ou Chroma)
- Orchestrer la recherche s√©mantique et la g√©n√©ration de r√©ponses

#### 3.3. Ollama : l'ex√©cution locale de mod√®les de langage

**Qu'est-ce qu'Ollama ?**

Ollama est un outil open-source qui permet d'ex√©cuter des mod√®les de langage (LLM) **localement** sur un ordinateur ou un serveur, sans d√©pendre d'API externes. Il simplifie consid√©rablement le t√©l√©chargement, la configuration et l'ex√©cution de mod√®les comme Llama, Mistral, Phi, etc.

**Pourquoi Ollama ?**

Pour une entreprise de t√©l√©communication, l'utilisation d'Ollama pr√©sente des avantages strat√©giques majeurs :

1. **Confidentialit√© totale** : Les donn√©es ne quittent jamais l'infrastructure de l'entreprise
2. **Ind√©pendance** : Pas de d√©pendance √† un fournisseur externe (OpenAI, Mistral AI)
3. **Co√ªt ma√Ætris√©** : Pas de facturation √† l'usage (nombre de tokens)
4. **Disponibilit√©** : Fonctionne m√™me sans connexion internet (important pour certains sites)
5. **Contr√¥le** : L'entreprise garde le contr√¥le total sur le mod√®le et son utilisation

**Contraintes et limites :**

- N√©cessite des ressources mat√©rielles (CPU/GPU, RAM)
- Performances inf√©rieures aux mod√®les propri√©taires de pointe (GPT-4, Claude)
- N√©cessite une expertise technique pour l'installation et la maintenance

**Strat√©gie hybride :**

Le projet proposera une **architecture flexible** permettant de basculer entre :
- **Ollama (local)** pour les donn√©es sensibles et l'usage quotidien
- **API externes** (Mistral AI, OpenAI) pour des cas d'usage n√©cessitant des performances maximales

#### 3.4. Choix du mod√®le de langage : Mistral 7B via Ollama

**Contrainte mat√©rielle :**

Le cahier des charges impose une contrainte forte : le syst√®me doit pouvoir fonctionner sur un PC avec **seulement 4 Go de RAM**. Cette contrainte √©limine d'embl√©e les mod√®les de grande taille (13B, 70B param√®tres).

**Mod√®le s√©lectionn√© : Mistral 7B (via Ollama)**

Apr√®s analyse des mod√®les disponibles sur Ollama compatibles avec 4 Go de RAM, nous recommandons **Mistral 7B** dans sa version quantifi√©e (Q4 ou Q5).

**Justification du choix :**

| Crit√®re | Justification |
|---------|---------------|
| **Taille** | ~4 Go en version quantifi√©e Q4, compatible avec la contrainte RAM |
| **Performance** | Excellent rapport qualit√©/taille, surpasse des mod√®les plus gros sur de nombreux benchmarks |
| **Langue fran√ßaise** | Tr√®s bonnes performances en fran√ßais, crucial pour notre cas d'usage |
| **Licence** | Apache 2.0, utilisable en entreprise sans restriction |
| **Support Ollama** | Officiellement support√©, installation simple (`ollama pull mistral`) |
| **Communaut√©** | Large adoption, nombreux retours d'exp√©rience |

**Alternatives consid√©r√©es :**

- **Phi-2 (2.7B)** : Plus l√©ger, mais performances inf√©rieures en fran√ßais
- **Llama 2 7B** : Comparable, mais Mistral montre de meilleures performances
- **Gemma 2B** : Trop petit, g√©n√©ration de qualit√© insuffisante pour le cas d'usage

**R√¥le du LLM dans le projet :**

Il est important de souligner que **le LLM n'est qu'un composant du syst√®me RAG**. La valeur principale du projet repose sur :

1. **La structuration de la connaissance** (choix des documents, d√©coupage, indexation)
2. **La qualit√© de la recherche s√©mantique** (embeddings, similarit√©)
3. **L'ing√©nierie des prompts** (instructions donn√©es au LLM)

Le LLM sert uniquement √† **reformuler et synth√©tiser** les informations trouv√©es dans les documents. Un mod√®le de 7B est donc largement suffisant pour cette t√¢che.

#### 3.5. Embeddings et base vectorielle

**Embeddings :**

Pour transformer les documents en vecteurs, nous utiliserons :
- **sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2** : Mod√®le d'embeddings multilingue, performant en fran√ßais, l√©ger (~120 Mo)

**Base vectorielle :**

Pour stocker et rechercher les vecteurs, deux options :
- **FAISS** (Facebook AI Similarity Search) : Tr√®s rapide, fonctionne en local, id√©al pour un MVP
- **Chroma** : Plus moderne, persistance native, √©volutif

Nous privil√©gierons **FAISS** pour sa simplicit√© et ses performances.

#### 3.6. Interface utilisateur : Streamlit

**Pourquoi Streamlit ?**

Streamlit est un framework Python permettant de cr√©er rapidement des interfaces web interactives.

**Avantages :**

- ‚úÖ **Rapidit√© de d√©veloppement** : Interface fonctionnelle en quelques lignes de code
- ‚úÖ **Int√©gration Python** : S'int√®gre naturellement avec LangChain et Ollama
- ‚úÖ **Accessibilit√©** : Interface web accessible depuis n'importe quel navigateur
- ‚úÖ **D√©ploiement simple** : Peut √™tre h√©berg√© sur un serveur interne ou cloud

**Fonctionnalit√©s de l'interface :**

- Zone de saisie pour poser des questions en langage naturel
- Affichage de la r√©ponse g√©n√©r√©e
- Affichage des sources documentaires utilis√©es
- Historique des conversations

#### 3.7. Synth√®se des choix technologiques

| Composant | Technologie | Justification |
|-----------|-------------|---------------|
| **Framework RAG** | LangChain | Standard de l'industrie, modularit√©, communaut√© |
| **LLM local** | Ollama + Mistral 7B | Confidentialit√©, compatibilit√© 4 Go RAM, performances |
| **Embeddings** | sentence-transformers (multilingual) | Qualit√© en fran√ßais, l√©ger |
| **Base vectorielle** | FAISS | Performance, simplicit√©, local |
| **Interface** | Streamlit | Rapidit√© de d√©veloppement, accessibilit√© web |
| **Langage** | Python 3.10+ | √âcosyst√®me IA/ML, compatibilit√© des librairies |

---

### 4. Architecture conceptuelle globale du syst√®me

L'architecture du syst√®me RAG propos√© s'articule autour de **quatre grandes phases** : l'ingestion des documents, l'indexation vectorielle, la recherche s√©mantique et la g√©n√©ration de r√©ponses. Nous d√©crivons ici l'architecture de mani√®re textuelle et fonctionnelle.

#### 4.1. Vue d'ensemble du syst√®me

Le syst√®me RAG fonctionne selon le flux suivant :

**Phase 1 ‚Äì Pr√©paration (hors ligne, une seule fois ou √† chaque mise √† jour)**

1. **Collecte des documents** : Rassemblement de la documentation interne (PDF, DOCX, TXT)
2. **Ingestion** : Chargement des documents via LangChain Document Loaders
3. **D√©coupage (Chunking)** : Division des documents en morceaux de texte de taille optimale (ex : 500-1000 caract√®res avec chevauchement)
4. **Vectorisation (Embeddings)** : Transformation de chaque chunk en vecteur num√©rique capturant son sens s√©mantique
5. **Indexation** : Stockage des vecteurs dans une base vectorielle (FAISS) pour une recherche rapide

**Phase 2 ‚Äì Utilisation (en ligne, √† chaque question)**

6. **Question utilisateur** : L'utilisateur pose une question en langage naturel via l'interface Streamlit
7. **Vectorisation de la question** : La question est transform√©e en vecteur avec le m√™me mod√®le d'embeddings
8. **Recherche s√©mantique** : Le syst√®me recherche les chunks les plus similaires √† la question dans la base vectorielle (top-k, ex : 5 chunks)
9. **Construction du contexte** : Les chunks pertinents sont assembl√©s pour former un contexte
10. **G√©n√©ration de la r√©ponse** : Le LLM (Mistral via Ollama) re√ßoit la question + le contexte et g√©n√®re une r√©ponse
11. **Affichage** : La r√©ponse et les sources sont affich√©es √† l'utilisateur

#### 4.2. Description d√©taill√©e des composants

**Composant 1 : Module d'ingestion et de pr√©traitement**

*R√¥le :* Charger les documents internes et les pr√©parer pour l'indexation.

*Fonctionnalit√©s :*
- Support de multiples formats (PDF, DOCX, TXT, HTML)
- Extraction du texte brut
- Nettoyage (suppression des caract√®res sp√©ciaux, normalisation)
- D√©coupage en chunks avec strat√©gie de chevauchement (overlap) pour pr√©server le contexte

*Technologies :* LangChain Document Loaders, Text Splitters (RecursiveCharacterTextSplitter)

**Composant 2 : Module de vectorisation**

*R√¥le :* Transformer le texte en repr√©sentations vectorielles exploitables pour la recherche s√©mantique.

*Fonctionnalit√©s :*
- G√©n√©ration d'embeddings pour chaque chunk
- G√©n√©ration d'embeddings pour les questions utilisateurs

*Technologies :* sentence-transformers (mod√®le multilingue), HuggingFace Embeddings via LangChain

**Composant 3 : Base vectorielle**

*R√¥le :* Stocker les vecteurs et permettre une recherche par similarit√© ultra-rapide.

*Fonctionnalit√©s :*
- Indexation des vecteurs avec m√©tadonn√©es (source, page, date)
- Recherche des k vecteurs les plus proches (k-NN)
- Persistance sur disque pour √©viter de r√©indexer √† chaque d√©marrage

*Technologies :* FAISS (Facebook AI Similarity Search)

**Composant 4 : Module de recherche (Retriever)**

*R√¥le :* Orchestrer la recherche s√©mantique pour trouver les passages pertinents.

*Fonctionnalit√©s :*
- R√©ception de la question utilisateur
- Vectorisation de la question
- Interrogation de la base vectorielle
- Retour des top-k chunks les plus pertinents avec leurs m√©tadonn√©es

*Technologies :* LangChain Retrievers (VectorStoreRetriever)

**Composant 5 : Mod√®le de langage (LLM)**

*R√¥le :* G√©n√©rer une r√©ponse en langage naturel √† partir de la question et du contexte r√©cup√©r√©.

*Fonctionnalit√©s :*
- R√©ception d'un prompt structur√© (instruction + contexte + question)
- G√©n√©ration d'une r√©ponse coh√©rente, synth√©tique et factuelle
- Possibilit√© de citer les sources utilis√©es

*Technologies :* Ollama (Mistral 7B) ou API externes (Mistral AI, OpenAI)

**Composant 6 : Module d'orchestration (Chain)**

*R√¥le :* Coordonner l'ensemble du pipeline RAG (recherche + g√©n√©ration).

*Fonctionnalit√©s :*
- Encha√Ænement automatique : question ‚Üí recherche ‚Üí g√©n√©ration ‚Üí r√©ponse
- Gestion des prompts (templates)
- Gestion de l'historique conversationnel (optionnel, pour des √©changes multi-tours)

*Technologies :* LangChain Chains (RetrievalQA, ConversationalRetrievalChain)

**Composant 7 : Interface utilisateur**

*R√¥le :* Permettre aux utilisateurs d'interagir avec le syst√®me de mani√®re intuitive.

*Fonctionnalit√©s :*
- Zone de saisie de question
- Affichage de la r√©ponse
- Affichage des sources (documents, pages)
- Historique des questions/r√©ponses
- Param√®tres (choix du mod√®le, nombre de sources, etc.)

*Technologies :* Streamlit

#### 4.3. Flux de donn√©es

**Flux d'ingestion (pr√©paration) :**

```
Documents internes (PDF, DOCX, TXT)
    ‚Üì
[Document Loader] ‚Üí Extraction du texte
    ‚Üì
[Text Splitter] ‚Üí D√©coupage en chunks
    ‚Üì
[Embedding Model] ‚Üí Vectorisation
    ‚Üì
[FAISS Vector Store] ‚Üí Indexation et stockage
```

**Flux de question-r√©ponse (utilisation) :**

```
Question utilisateur (interface Streamlit)
    ‚Üì
[Embedding Model] ‚Üí Vectorisation de la question
    ‚Üì
[FAISS Vector Store] ‚Üí Recherche de similarit√© ‚Üí Top-k chunks pertinents
    ‚Üì
[Prompt Template] ‚Üí Construction du prompt (contexte + question)
    ‚Üì
[LLM - Mistral via Ollama] ‚Üí G√©n√©ration de la r√©ponse
    ‚Üì
[Interface Streamlit] ‚Üí Affichage de la r√©ponse + sources
```

#### 4.4. Strat√©gie de d√©ploiement : on-premise vs cloud

**Option 1 : D√©ploiement on-premise (recommand√© pour les t√©l√©coms)**

*Description :* L'ensemble du syst√®me (base vectorielle, LLM via Ollama, interface Streamlit) est h√©berg√© sur les serveurs internes de l'entreprise.

*Avantages :*
- ‚úÖ **Confidentialit√© maximale** : Les donn√©es ne quittent jamais l'infrastructure
- ‚úÖ **Conformit√© r√©glementaire** : Respect des politiques de s√©curit√© strictes
- ‚úÖ **Ind√©pendance** : Pas de d√©pendance √† un fournisseur cloud
- ‚úÖ **Latence faible** : Acc√®s rapide depuis le r√©seau interne

*Contraintes :*
- ‚ö†Ô∏è N√©cessite des ressources mat√©rielles (serveur avec GPU recommand√© pour Ollama)
- ‚ö†Ô∏è N√©cessite une expertise IT pour l'installation et la maintenance
- ‚ö†Ô∏è Acc√®s √† distance n√©cessite un VPN ou une infrastructure s√©curis√©e

*Cas d'usage :* Entreprises avec des exigences de s√©curit√© √©lev√©es (Orange, Expresso)

**Option 2 : D√©ploiement cloud hybride**

*Description :* L'interface et la base vectorielle sont h√©berg√©es sur un cloud priv√© ou public, le LLM peut √™tre local (Ollama) ou via API.

*Avantages :*
- ‚úÖ **Scalabilit√©** : Adaptation automatique aux pics de charge
- ‚úÖ **Accessibilit√©** : Acc√®s depuis n'importe o√π sans VPN
- ‚úÖ **Maintenance simplifi√©e** : G√©r√©e par le fournisseur cloud

*Contraintes :*
- ‚ö†Ô∏è D√©pendance √† un fournisseur cloud
- ‚ö†Ô∏è Co√ªts r√©currents
- ‚ö†Ô∏è N√©cessite une analyse de risque pour les donn√©es sensibles

*Cas d'usage :* Entreprises avec une politique cloud √©tablie, ou pour un MVP/pilote

**Option 3 : Architecture hybride (recommandation finale)**

*Description :* 
- **Donn√©es sensibles et LLM** : On-premise (serveur interne + Ollama)
- **Interface utilisateur** : Cloud (Streamlit Cloud ou serveur web interne)
- **Connexion s√©curis√©e** : API interne entre l'interface et le backend RAG

*Avantages :*
- ‚úÖ Meilleur compromis s√©curit√©/accessibilit√©
- ‚úÖ Flexibilit√© de d√©ploiement

#### 4.5. Consid√©rations de s√©curit√© et de confidentialit√©

Pour une entreprise de t√©l√©communication, la s√©curit√© des donn√©es est primordiale. Le syst√®me doit int√©grer :

**S√©curit√© des donn√©es :**
- Chiffrement des documents au repos et en transit
- Contr√¥le d'acc√®s bas√© sur les r√¥les (RBAC)
- Logs d'audit des requ√™tes et acc√®s

**Confidentialit√© :**
- Aucune donn√©e envoy√©e √† des services externes (si Ollama local)
- Anonymisation des logs si n√©cessaire
- Conformit√© RGPD pour les donn√©es personnelles

**Disponibilit√© :**
- Sauvegardes r√©guli√®res de la base vectorielle
- Monitoring de la disponibilit√© du service
- Plan de reprise d'activit√©

#### 4.6. √âvolutivit√© de l'architecture

L'architecture propos√©e est con√ßue pour √©voluer :

**Court terme (MVP) :**
- Base documentaire limit√©e (~100-200 documents)
- Mod√®le Mistral 7B via Ollama
- Interface Streamlit simple
- D√©ploiement sur un serveur unique

**Moyen terme (Production) :**
- Extension de la base documentaire (milliers de documents)
- Ajout de fonctionnalit√©s (historique, multi-utilisateurs, analytics)
- Optimisation des performances (GPU, cache)
- D√©ploiement distribu√© (load balancing)

**Long terme (√âvolutions avanc√©es) :**
- Fine-tuning du mod√®le sur les donn√©es t√©l√©com
- Int√©gration avec les syst√®mes existants (CRM, ERP)
- Support multilingue (wolof, anglais)
- Analyse des tendances de questions pour am√©liorer la documentation

---

## üéØ FIN DE LA PARTIE 1

**La PARTIE 1 est maintenant termin√©e.**

Cette premi√®re partie a permis de :
- ‚úÖ Contextualiser le projet dans l'environnement des t√©l√©communications
- ‚úÖ Identifier clairement la probl√©matique et les besoins
- ‚úÖ D√©finir des objectifs fonctionnels, techniques et p√©dagogiques
- ‚úÖ Justifier les choix technologiques (RAG, LangChain, Ollama, Mistral 7B)
- ‚úÖ D√©crire l'architecture conceptuelle globale du syst√®me

**Prochaine √©tape : PARTIE 2**

La PARTIE 2 abordera la mise en ≈ìuvre concr√®te du syst√®me :
- Configuration de l'environnement de travail
- Installation et configuration d'Ollama et Mistral
- Constitution de la base de connaissances t√©l√©com
- Impl√©mentation du pipeline RAG avec LangChain
- D√©ploiement et h√©bergement (on-premise/cloud)
- D√©veloppement de l'interface Streamlit
- Tests et validation
- Limites et perspectives d'am√©lioration

---

**üìÖ Document r√©dig√© dans le cadre d'un projet acad√©mique**  
**üéì Intelligence Artificielle Appliqu√©e ‚Äì RAG et LLM**  
**üè¢ Cas d'usage : Entreprise de t√©l√©communication (S√©n√©gal)**

---

## üé® Charte graphique inspir√©e de YAS (Op√©rateur t√©l√©com)

Pour l'interface utilisateur et les supports visuels du projet, nous nous inspirerons de la charte graphique de **YAS**, op√©rateur t√©l√©com innovant :

**Couleurs principales :**
- **Violet YAS** : `#6B2D8F` (couleur signature, modernit√©, innovation)
- **Blanc** : `#FFFFFF` (clart√©, simplicit√©)
- **Gris fonc√©** : `#2C2C2C` (texte, contraste)
- **Vert accent** : `#00D9A3` (succ√®s, validation, √©l√©ments interactifs)

**Typographie :**
- Titres : **Montserrat Bold**
- Corps de texte : **Open Sans Regular**

**Principes de design :**
- Interface √©pur√©e et moderne
- Utilisation du violet comme couleur dominante
- Accents verts pour les actions positives
- Espaces blancs g√©n√©reux pour la lisibilit√©

Cette identit√© visuelle rappellera l'environnement t√©l√©com tout en apportant une touche moderne et professionnelle au projet.

---

## PARTIE 2 ‚Äì MISE EN PLACE TECHNIQUE, H√âBERGEMENT ET PREMI√àRE √âVOLUTION DU PROJET

### 2.1. Mise en place de l'environnement de travail

La mise en ≈ìuvre du syst√®me RAG n√©cessite un environnement de d√©veloppement structur√© et reproductible. Cette section d√©taille les pr√©requis, l'installation des d√©pendances et l'organisation du projet.

#### 2.1.1. Pr√©requis syst√®me

**Configuration mat√©rielle minimale :**

| Composant | Sp√©cification minimale | Sp√©cification recommand√©e |
|-----------|------------------------|---------------------------|
| **Processeur** | Intel Core i5 / AMD Ryzen 5 (4 c≈ìurs) | Intel Core i7 / AMD Ryzen 7 (8 c≈ìurs) |
| **RAM** | 4 Go (contrainte du projet) | 8-16 Go pour de meilleures performances |
| **Stockage** | 10 Go d'espace libre (SSD recommand√©) | 20 Go (SSD) |
| **GPU** | Optionnel (CPU suffisant pour Mistral 7B) | NVIDIA GPU avec 6+ Go VRAM (acc√©l√©ration) |
| **Syst√®me d'exploitation** | Windows 10/11, Linux (Ubuntu 20.04+), macOS 12+ | Linux Ubuntu 22.04 LTS (optimal pour serveur) |

**Logiciels requis :**

- **Python** : Version 3.10 ou 3.11 (3.12 peut avoir des incompatibilit√©s avec certaines librairies)
- **pip** : Gestionnaire de paquets Python (inclus avec Python)
- **Git** : Pour la gestion de version (optionnel mais recommand√©)
- **Ollama** : Pour l'ex√©cution locale de Mistral 7B

#### 2.1.2. Installation de Python et cr√©ation de l'environnement virtuel

**√âtape 1 : V√©rification de l'installation Python**

```bash
# V√©rifier la version de Python install√©e
python --version
# ou
python3 --version

# Devrait afficher : Python 3.10.x ou 3.11.x
```

**√âtape 2 : Cr√©ation d'un environnement virtuel**

L'utilisation d'un environnement virtuel est une **bonne pratique essentielle** pour :
- Isoler les d√©pendances du projet
- √âviter les conflits entre diff√©rents projets
- Faciliter le d√©ploiement et la reproduction de l'environnement

```bash
# Cr√©er un dossier pour le projet
mkdir telecom_rag_project
cd telecom_rag_project

# Cr√©er un environnement virtuel nomm√© 'venv'
python -m venv venv

# Activer l'environnement virtuel
# Sur Windows :
venv\Scripts\activate
# Sur Linux/macOS :
source venv/bin/activate

# Une fois activ√©, le prompt affiche (venv)
```

**√âtape 3 : Mise √† jour de pip**

```bash
# Mettre √† jour pip vers la derni√®re version
pip install --upgrade pip
```

#### 2.1.3. Installation des d√©pendances Python

**Cr√©ation du fichier `requirements.txt`**

Ce fichier liste toutes les librairies Python n√©cessaires au projet :

```
# Framework RAG et LLM
langchain==0.1.0
langchain-community==0.0.10

# Mod√®le d'embeddings
sentence-transformers==2.2.2

# Base vectorielle
faiss-cpu==1.7.4
# Note : utiliser faiss-gpu si GPU disponible

# Chargement de documents
pypdf==3.17.4
python-docx==1.1.0
unstructured==0.11.0

# Interface utilisateur
streamlit==1.29.0

# Utilitaires
python-dotenv==1.0.0
tiktoken==0.5.2

# Ollama (client Python)
ollama==0.1.0
```

**Installation des d√©pendances :**

```bash
# Installer toutes les d√©pendances
pip install -r requirements.txt

# V√©rification de l'installation
pip list
```

**Remarques importantes :**

- **faiss-cpu vs faiss-gpu** : Utiliser `faiss-cpu` pour un PC sans GPU, `faiss-gpu` si GPU NVIDIA disponible
- **unstructured** : Permet de charger des formats complexes (HTML, Markdown, etc.)
- **tiktoken** : Utilis√© pour compter les tokens et optimiser les prompts

#### 2.1.4. Structure du projet

Organisation recommand√©e des fichiers et dossiers :

```
telecom_rag_project/
‚îÇ
‚îú‚îÄ‚îÄ venv/                          # Environnement virtuel (ne pas versionner)
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Donn√©es du projet
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # Documents bruts (PDF, DOCX)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ offres_commerciales/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ procedures_techniques/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ conditions_generales/
‚îÇ   ‚îî‚îÄ‚îÄ processed/                 # Documents trait√©s (optionnel)
‚îÇ
‚îú‚îÄ‚îÄ vectorstore/                   # Base vectorielle FAISS (persistance)
‚îÇ   ‚îî‚îÄ‚îÄ faiss_index/
‚îÇ
‚îú‚îÄ‚îÄ src/                           # Code source
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py             # Chargement et d√©coupage des documents
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py              # Gestion des embeddings
‚îÇ   ‚îú‚îÄ‚îÄ vectorstore.py             # Gestion de la base vectorielle
‚îÇ   ‚îú‚îÄ‚îÄ llm.py                     # Configuration du LLM (Ollama)
‚îÇ   ‚îú‚îÄ‚îÄ rag_pipeline.py            # Pipeline RAG complet
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                   # Fonctions utilitaires
‚îÇ
‚îú‚îÄ‚îÄ app/                           # Interface Streamlit
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                     # Notebooks Jupyter (exp√©rimentation)
‚îÇ   ‚îî‚îÄ‚îÄ rag_experimentation.ipynb
‚îÇ
‚îú‚îÄ‚îÄ config/                        # Fichiers de configuration
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îÇ
‚îú‚îÄ‚îÄ .env                           # Variables d'environnement (API keys)
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                      # Documentation du projet
‚îî‚îÄ‚îÄ .gitignore                     # Fichiers √† ignorer par Git
```

**Fichier `.gitignore` recommand√© :**

```
# Environnement virtuel
venv/
env/

# Base vectorielle (peut √™tre volumineuse)
vectorstore/

# Variables d'environnement (secrets)
.env

# Cache Python
__pycache__/
*.pyc

# Notebooks
.ipynb_checkpoints/

# Donn√©es sensibles
data/raw/
```

---

### 2.2. Choix et configuration du mod√®le de langage

Cette section d√©taille l'installation d'Ollama, le t√©l√©chargement de Mistral 7B, et la configuration pour une utilisation optimale dans le contexte t√©l√©com.

#### 2.2.1. Installation d'Ollama

**Qu'est-ce qu'Ollama ?**

Ollama est un outil qui simplifie l'ex√©cution de mod√®les de langage localement. Il g√®re automatiquement :
- Le t√©l√©chargement des mod√®les
- La quantification (compression) pour r√©duire l'utilisation de la RAM
- L'exposition d'une API locale (compatible OpenAI)
- L'optimisation des performances selon le mat√©riel

**Installation selon le syst√®me d'exploitation :**

**Sur Linux :**
```bash
# Installation en une commande
curl -fsSL https://ollama.com/install.sh | sh

# V√©rification de l'installation
ollama --version
```

**Sur macOS :**
```bash
# T√©l√©charger depuis https://ollama.com/download
# Ou via Homebrew :
brew install ollama
```

**Sur Windows :**
```
1. T√©l√©charger l'installeur depuis https://ollama.com/download
2. Ex√©cuter OllamaSetup.exe
3. Suivre l'assistant d'installation
4. V√©rifier dans PowerShell : ollama --version
```

**D√©marrage du service Ollama :**

```bash
# D√©marrer Ollama en arri√®re-plan
ollama serve

# Le service √©coute par d√©faut sur http://localhost:11434
```

#### 2.2.2. T√©l√©chargement et configuration de Mistral 7B

**T√©l√©chargement du mod√®le :**

```bash
# T√©l√©charger Mistral 7B (version quantifi√©e Q4)
ollama pull mistral

# Cela t√©l√©charge environ 4 Go de donn√©es
# La version par d√©faut est optimis√©e pour un bon compromis qualit√©/taille
```

**Versions disponibles de Mistral :**

| Version | Taille | RAM requise | Qualit√© | Recommandation |
|---------|--------|-------------|---------|----------------|
| `mistral:7b-instruct-q2_K` | ~2.5 Go | 3 Go | Faible | Non recommand√© |
| `mistral:7b-instruct-q4_0` | ~4 Go | 4-5 Go | Bonne | **Recommand√© pour 4 Go RAM** |
| `mistral:7b-instruct-q5_K_M` | ~5 Go | 6 Go | Tr√®s bonne | Si 8 Go RAM disponible |
| `mistral:7b-instruct` | ~7 Go | 8 Go | Excellente | Si 16 Go RAM disponible |

Pour notre contrainte de **4 Go de RAM**, nous utilisons la version **Q4** (par d√©faut).

**Test du mod√®le :**

```bash
# Tester Mistral en mode interactif
ollama run mistral

# Poser une question de test :
# >>> Quelles sont les principales offres d'un op√©rateur t√©l√©com ?
# Le mod√®le devrait g√©n√©rer une r√©ponse coh√©rente en fran√ßais

# Quitter : /bye
```

#### 2.2.3. Configuration de l'API Ollama pour LangChain

**Cr√©ation du fichier `.env` pour les configurations :**

```bash
# Fichier .env √† la racine du projet
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
CHUNK_SIZE=800
CHUNK_OVERLAP=200
TOP_K_RETRIEVAL=5
```

**Explication des param√®tres :**

- **OLLAMA_BASE_URL** : URL de l'API Ollama (local par d√©faut)
- **OLLAMA_MODEL** : Nom du mod√®le √† utiliser
- **EMBEDDING_MODEL** : Mod√®le pour g√©n√©rer les embeddings
- **CHUNK_SIZE** : Taille des morceaux de texte (en caract√®res)
- **CHUNK_OVERLAP** : Chevauchement entre chunks (pour pr√©server le contexte)
- **TOP_K_RETRIEVAL** : Nombre de documents pertinents √† r√©cup√©rer

#### 2.2.4. Alternative : Utilisation d'API externes (Mistral AI, OpenAI)

Pour des cas d'usage n√©cessitant des performances maximales, le syst√®me peut basculer vers des API externes.

**Configuration pour Mistral AI :**

```bash
# Ajouter dans .env
MISTRAL_API_KEY=votre_cl√©_api_mistral
MISTRAL_MODEL=mistral-medium
```

**Configuration pour OpenAI :**

```bash
# Ajouter dans .env
OPENAI_API_KEY=votre_cl√©_api_openai
OPENAI_MODEL=gpt-3.5-turbo
```

**Avantages et inconv√©nients :**

| Crit√®re | Ollama (local) | API externe |
|---------|----------------|-------------|
| **Confidentialit√©** | ‚úÖ Totale | ‚ùå Donn√©es envoy√©es √† l'ext√©rieur |
| **Co√ªt** | ‚úÖ Gratuit (apr√®s achat mat√©riel) | ‚ùå Facturation √† l'usage |
| **Performance** | ‚ö†Ô∏è D√©pend du mat√©riel | ‚úÖ Tr√®s √©lev√©e |
| **Disponibilit√©** | ‚úÖ Fonctionne hors ligne | ‚ùå N√©cessite internet |
| **Latence** | ‚úÖ Faible (local) | ‚ö†Ô∏è D√©pend de la connexion |

**Recommandation pour les t√©l√©coms :** Privil√©gier Ollama pour la production, utiliser les API pour les tests et benchmarks.

---

### 2.3. Constitution d'une premi√®re base de connaissances t√©l√©com

La qualit√© du syst√®me RAG d√©pend directement de la qualit√© et de la pertinence de la base documentaire. Cette section d√©crit comment constituer une base de connaissances repr√©sentative pour un op√©rateur t√©l√©com.

#### 2.3.1. Identification des documents sources

**Cat√©gories de documents √† inclure :**

**1. Offres commerciales**
- Fiches produits (forfaits mobile, internet fixe, entreprise)
- Grilles tarifaires
- Conditions promotionnelles
- Comparatifs d'offres

**2. Proc√©dures techniques**
- Proc√©dures d'activation de services
- Guides de configuration (APN, MMS, internet mobile)
- Proc√©dures de portabilit√© de num√©ro
- R√©solution de probl√®mes courants (FAQ technique)

**3. Conditions contractuelles**
- Conditions G√©n√©rales de Vente (CGV)
- Conditions G√©n√©rales d'Utilisation (CGU)
- Politiques de r√©siliation
- Clauses de responsabilit√©

**4. SLA et engagements de service**
- Temps de r√©tablissement garantis
- Niveaux de disponibilit√©
- Proc√©dures d'escalade
- Compensations en cas de non-respect

**5. Documentation support client**
- Scripts d'appel pour les agents
- Arbres de d√©cision pour le diagnostic
- Proc√©dures de remboursement
- Gestion des r√©clamations

#### 2.3.2. Exemple de base documentaire pour un MVP

Pour un **Minimum Viable Product (MVP)**, nous recommandons de commencer avec un √©chantillon repr√©sentatif :

**Base documentaire initiale (15-20 documents) :**

| Document | Format | Pages | Objectif |
|----------|--------|-------|----------|
| Catalogue offres mobiles 2024 | PDF | 10 | Conna√Ætre les forfaits disponibles |
| Grille tarifaire entreprise | PDF | 5 | Tarifs B2B |
| CGV Orange S√©n√©gal | PDF | 25 | Conditions contractuelles |
| Proc√©dure activation 4G | DOCX | 3 | Support technique |
| FAQ portabilit√© num√©ro | PDF | 8 | Questions fr√©quentes |
| SLA clients entreprise | PDF | 12 | Engagements de service |
| Guide configuration APN | PDF | 4 | Support technique |
| Politique de r√©siliation | PDF | 6 | Conditions de sortie |
| Promotions en cours | PDF | 5 | Offres temporaires |
| Proc√©dure r√©clamation | DOCX | 7 | Gestion des litiges |

**Total estim√© :** ~85 pages, ~150-200 chunks apr√®s d√©coupage

#### 2.3.3. Pr√©paration et nettoyage des documents

**Bonnes pratiques avant l'ingestion :**

1. **V√©rifier la qualit√© des PDF**
   - Pr√©f√©rer les PDF textuels aux PDF scann√©s (OCR n√©cessaire sinon)
   - V√©rifier que le texte est s√©lectionnable

2. **Normaliser les noms de fichiers**
   - Utiliser des noms descriptifs : `offres_mobiles_2024.pdf` plut√¥t que `doc1.pdf`
   - √âviter les caract√®res sp√©ciaux et espaces

3. **Organiser par cat√©gorie**
   - Cr√©er des sous-dossiers dans `data/raw/`
   - Facilite la gestion et la tra√ßabilit√©

4. **Ajouter des m√©tadonn√©es**
   - Date de cr√©ation/mise √† jour
   - Cat√©gorie (commercial, technique, juridique)
   - Niveau de confidentialit√©

**Exemple de structure :**

```
data/raw/
‚îú‚îÄ‚îÄ offres_commerciales/
‚îÇ   ‚îú‚îÄ‚îÄ catalogue_mobile_2024.pdf
‚îÇ   ‚îú‚îÄ‚îÄ grille_tarifaire_entreprise.pdf
‚îÇ   ‚îî‚îÄ‚îÄ promotions_janvier_2024.pdf
‚îú‚îÄ‚îÄ procedures_techniques/
‚îÇ   ‚îú‚îÄ‚îÄ activation_4g.docx
‚îÇ   ‚îú‚îÄ‚îÄ configuration_apn.pdf
‚îÇ   ‚îî‚îÄ‚îÄ portabilite_numero.pdf
‚îî‚îÄ‚îÄ conditions_generales/
    ‚îú‚îÄ‚îÄ cgv_orange_senegal.pdf
    ‚îî‚îÄ‚îÄ politique_resiliation.pdf
```

#### 2.3.4. Strat√©gie de mise √† jour de la base

**Probl√©matique :** Les offres t√©l√©com √©voluent fr√©quemment (nouvelles promotions, changements tarifaires, nouvelles r√©glementations).

**Solution : Processus de mise √† jour structur√©**

1. **Versioning des documents**
   - Inclure la date dans le nom : `offres_mobiles_2024_01.pdf`
   - Archiver les anciennes versions

2. **R√©indexation incr√©mentale**
   - Ajouter de nouveaux documents sans tout r√©indexer
   - Supprimer les documents obsol√®tes de la base vectorielle

3. **Notification des changements**
   - Alerter les utilisateurs lors de mises √† jour majeures
   - Afficher la date de derni√®re mise √† jour dans l'interface

4. **Automatisation (√©volution future)**
   - Script de surveillance d'un dossier partag√©
   - R√©indexation automatique lors de l'ajout de nouveaux fichiers

---

### 2.4. Impl√©mentation d'un premier pipeline RAG

Cette section d√©taille l'impl√©mentation concr√®te du pipeline RAG avec LangChain, de l'ingestion des documents √† la g√©n√©ration de r√©ponses.

#### 2.4.1. Chargement et d√©coupage des documents

**Fichier : `src/data_loader.py`**

Ce module g√®re le chargement des documents et leur d√©coupage en chunks.

**Fonctionnalit√©s :**

- Chargement de PDF, DOCX, TXT
- D√©coupage avec strat√©gie de chevauchement
- Extraction des m√©tadonn√©es (nom du fichier, page)

**Strat√©gie de d√©coupage (chunking) :**

Le d√©coupage est crucial pour la qualit√© du RAG. Nous utilisons une strat√©gie **r√©cursive** qui :
- D√©coupe d'abord par paragraphes
- Si un paragraphe est trop long, d√©coupe par phrases
- Si une phrase est trop longue, d√©coupe par caract√®res

**Param√®tres optimaux pour le t√©l√©com :**

- **Chunk size** : 800 caract√®res (~150-200 mots)
  - Assez long pour capturer le contexte
  - Assez court pour rester pertinent
- **Overlap** : 200 caract√®res (~40 mots)
  - Pr√©serve le contexte entre chunks
  - √âvite de couper des informations li√©es

**Exemple de logique :**

```
Document original (3000 caract√®res)
    ‚Üì
Chunk 1 : caract√®res 0-800
Chunk 2 : caract√®res 600-1400 (overlap de 200)
Chunk 3 : caract√®res 1200-2000 (overlap de 200)
Chunk 4 : caract√®res 1800-2600 (overlap de 200)
Chunk 5 : caract√®res 2400-3000 (overlap de 200)
```

#### 2.4.2. G√©n√©ration des embeddings

**Fichier : `src/embeddings.py`**

Ce module g√®re la g√©n√©ration des embeddings (repr√©sentations vectorielles du texte).

**Mod√®le d'embeddings choisi :**

`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`

**Caract√©ristiques :**

- **Multilingue** : Supporte le fran√ßais, l'anglais et 50+ langues
- **Taille** : ~120 Mo (l√©ger)
- **Dimensions** : 384 (vecteurs de 384 dimensions)
- **Performance** : Excellent compromis qualit√©/vitesse

**Processus de vectorisation :**

1. Chaque chunk de texte est transform√© en un vecteur de 384 dimensions
2. Ce vecteur capture le **sens s√©mantique** du texte
3. Des textes similaires en sens auront des vecteurs proches dans l'espace vectoriel

**Exemple conceptuel :**

```
Texte : "Le forfait Orange Pro 100 Go co√ªte 25 000 FCFA par mois"
    ‚Üì
Embedding : [0.23, -0.45, 0.12, ..., 0.67] (384 valeurs)

Texte similaire : "L'offre professionnelle 100 Go d'Orange est √† 25k FCFA/mois"
    ‚Üì
Embedding : [0.25, -0.43, 0.14, ..., 0.65] (tr√®s proche du premier)
```

#### 2.4.3. Indexation dans FAISS

**Fichier : `src/vectorstore.py`**

Ce module g√®re la cr√©ation et la gestion de la base vectorielle FAISS.

**Qu'est-ce que FAISS ?**

FAISS (Facebook AI Similarity Search) est une biblioth√®que optimis√©e pour :
- Stocker des millions de vecteurs
- Rechercher les k vecteurs les plus proches (k-NN) en millisecondes
- Fonctionner sur CPU ou GPU

**Processus d'indexation :**

1. **Cr√©ation de l'index FAISS**
   - Type d'index : `IndexFlatL2` (recherche exacte par distance L2)
   - Adapt√© pour des bases de taille petite √† moyenne (<100k vecteurs)

2. **Ajout des vecteurs**
   - Chaque chunk est transform√© en vecteur
   - Le vecteur est ajout√© √† l'index avec ses m√©tadonn√©es

3. **Persistance sur disque**
   - L'index est sauvegard√© dans `vectorstore/faiss_index/`
   - Permet de recharger l'index sans r√©indexer √† chaque d√©marrage

**M√©tadonn√©es stock√©es avec chaque vecteur :**

- Texte du chunk
- Nom du document source
- Num√©ro de page (si applicable)
- Cat√©gorie (commercial, technique, juridique)
- Date de derni√®re mise √† jour

#### 2.4.4. Recherche s√©mantique (Retrieval)

**Processus de recherche :**

1. **Question utilisateur** : "Quelles sont les conditions de r√©siliation d'un forfait entreprise ?"

2. **Vectorisation de la question** : La question est transform√©e en vecteur avec le m√™me mod√®le d'embeddings

3. **Recherche de similarit√©** : FAISS recherche les k chunks les plus proches (ex : k=5)

4. **Calcul de distance** : Pour chaque chunk, FAISS calcule la distance L2 entre le vecteur de la question et le vecteur du chunk

5. **Classement** : Les chunks sont class√©s par ordre de pertinence (distance croissante)

6. **Retour des r√©sultats** : Les top-k chunks sont retourn√©s avec leurs m√©tadonn√©es

**Exemple de r√©sultats :**

```
Question : "Quelles sont les conditions de r√©siliation d'un forfait entreprise ?"

R√©sultats (top 3) :
1. [Distance: 0.45] Source: politique_resiliation.pdf, Page 3
   "Pour r√©silier un forfait entreprise, le client doit envoyer..."

2. [Distance: 0.52] Source: cgv_orange_senegal.pdf, Page 18
   "Les conditions de r√©siliation anticip√©e pr√©voient..."

3. [Distance: 0.58] Source: faq_resiliation.pdf, Page 2
   "Q: Comment r√©silier mon abonnement professionnel ? R: ..."
```

#### 2.4.5. G√©n√©ration de la r√©ponse avec le LLM

**Fichier : `src/llm.py`**

Ce module g√®re l'interaction avec Ollama (Mistral 7B).

**Construction du prompt :**

Le prompt est structur√© en trois parties :

1. **Instruction syst√®me** : D√©finit le r√¥le et les contraintes du LLM
2. **Contexte** : Les chunks pertinents r√©cup√©r√©s par la recherche
3. **Question** : La question de l'utilisateur

**Exemple de prompt :**

```
[INSTRUCTION]
Tu es un assistant intelligent pour une entreprise de t√©l√©communication.
Ta mission est de r√©pondre aux questions des employ√©s en te basant UNIQUEMENT 
sur les documents internes fournis ci-dessous.

R√àGLES IMPORTANTES :
- R√©ponds en fran√ßais de mani√®re claire et professionnelle
- Base-toi UNIQUEMENT sur le contexte fourni
- Si l'information n'est pas dans le contexte, dis "Je ne trouve pas cette 
  information dans les documents disponibles"
- Cite toujours la source de l'information (nom du document)
- Sois pr√©cis et factuel

[CONTEXTE]
Document: politique_resiliation.pdf (Page 3)
Pour r√©silier un forfait entreprise, le client doit envoyer une lettre 
recommand√©e avec accus√© de r√©ception au moins 30 jours avant la date 
souhait√©e de r√©siliation. Des frais de r√©siliation anticip√©e de 50% du 
montant restant d√ª peuvent s'appliquer si le contrat est r√©sili√© avant 
la fin de la p√©riode d'engagement.

Document: cgv_orange_senegal.pdf (Page 18)
Les conditions de r√©siliation anticip√©e pr√©voient un pr√©avis de 30 jours 
calendaires. Le client reste redevable des mensualit√©s jusqu'√† la date 
effective de r√©siliation.

[QUESTION]
Quelles sont les conditions de r√©siliation d'un forfait entreprise ?

[R√âPONSE]
```

**G√©n√©ration de la r√©ponse :**

Le LLM (Mistral 7B via Ollama) g√©n√®re une r√©ponse en synth√©tisant les informations du contexte :

```
Pour r√©silier un forfait entreprise, voici les conditions √† respecter :

1. **Pr√©avis** : Vous devez respecter un pr√©avis de 30 jours calendaires 
   avant la date souhait√©e de r√©siliation.

2. **Proc√©dure** : Envoyez une lettre recommand√©e avec accus√© de r√©ception 
   √† l'op√©rateur.

3. **Frais de r√©siliation anticip√©e** : Si vous r√©siliez avant la fin de 
   votre p√©riode d'engagement, des frais de r√©siliation anticip√©e peuvent 
   s'appliquer, correspondant √† 50% du montant restant d√ª.

4. **Paiement des mensualit√©s** : Vous restez redevable des mensualit√©s 
   jusqu'√† la date effective de r√©siliation.

**Sources** : politique_resiliation.pdf (Page 3), cgv_orange_senegal.pdf (Page 18)
```

#### 2.4.6. Pipeline RAG complet

**Fichier : `src/rag_pipeline.py`**

Ce module orchestre l'ensemble du pipeline RAG.

**Flux complet :**

```
1. Utilisateur pose une question
    ‚Üì
2. Vectorisation de la question (embeddings.py)
    ‚Üì
3. Recherche dans FAISS (vectorstore.py)
    ‚Üì
4. R√©cup√©ration des top-k chunks pertinents
    ‚Üì
5. Construction du prompt (contexte + question)
    ‚Üì
6. Envoi au LLM Mistral via Ollama (llm.py)
    ‚Üì
7. G√©n√©ration de la r√©ponse
    ‚Üì
8. Retour de la r√©ponse + sources √† l'utilisateur
```

**Optimisations impl√©ment√©es :**

- **Cache des embeddings** : √âvite de recalculer les embeddings des documents
- **Limitation de la taille du contexte** : Maximum 3000 tokens pour √©viter de d√©passer la fen√™tre du LLM
- **Filtrage des chunks redondants** : √âvite d'envoyer plusieurs fois le m√™me passage
- **Gestion des erreurs** : Fallback si Ollama n'est pas disponible

---

### 2.5. H√©bergement et d√©ploiement de la solution

Cette section aborde les diff√©rentes strat√©gies de d√©ploiement adapt√©es aux contraintes de s√©curit√© et de confidentialit√© des entreprises de t√©l√©communication.

#### 2.5.1. D√©ploiement on-premise (sur serveur interne)

**Contexte :**

Pour une entreprise de t√©l√©communication manipulant des donn√©es sensibles (informations clients, strat√©gies commerciales, SLA confidentiels), le d√©ploiement **on-premise** (sur les serveurs internes de l'entreprise) est la solution privil√©gi√©e.

**Architecture on-premise :**

```
R√©seau interne de l'entreprise
‚îÇ
‚îú‚îÄ‚îÄ Serveur RAG (Linux Ubuntu 22.04 LTS)
‚îÇ   ‚îú‚îÄ‚îÄ Ollama + Mistral 7B (port 11434)
‚îÇ   ‚îú‚îÄ‚îÄ Application Python (pipeline RAG)
‚îÇ   ‚îú‚îÄ‚îÄ Base vectorielle FAISS (stockage local)
‚îÇ   ‚îî‚îÄ‚îÄ Interface Streamlit (port 8501)
‚îÇ
‚îú‚îÄ‚îÄ Serveur de fichiers (stockage documents)
‚îÇ   ‚îî‚îÄ‚îÄ Documents internes (PDF, DOCX)
‚îÇ
‚îî‚îÄ‚îÄ Postes clients (acc√®s via navigateur)
    ‚îî‚îÄ‚îÄ http://serveur-rag.interne:8501
```

**Avantages :**

‚úÖ **Confidentialit√© maximale** : Les donn√©es ne quittent jamais l'infrastructure  
‚úÖ **Conformit√© r√©glementaire** : Respect des politiques de s√©curit√© strictes  
‚úÖ **Contr√¥le total** : Ma√Ætrise compl√®te de l'infrastructure  
‚úÖ **Latence faible** : Acc√®s rapide depuis le r√©seau local  
‚úÖ **Ind√©pendance** : Pas de d√©pendance √† un fournisseur cloud  

**Contraintes :**

‚ö†Ô∏è **Investissement mat√©riel** : Achat/allocation d'un serveur d√©di√©  
‚ö†Ô∏è **Expertise technique** : N√©cessite des comp√©tences IT pour l'installation et la maintenance  
‚ö†Ô∏è **Scalabilit√© limit√©e** : D√©pend des ressources mat√©rielles disponibles  
‚ö†Ô∏è **Acc√®s distant** : N√©cessite un VPN pour l'acc√®s hors site  

**Configuration serveur recommand√©e :**

| Composant | Sp√©cification |
|-----------|---------------|
| **Processeur** | Intel Xeon / AMD EPYC (8+ c≈ìurs) |
| **RAM** | 16-32 Go (pour g√©rer plusieurs utilisateurs simultan√©s) |
| **Stockage** | 500 Go SSD (syst√®me + documents + base vectorielle) |
| **GPU** | Optionnel : NVIDIA Tesla T4 ou √©quivalent (acc√©l√©ration) |
| **OS** | Ubuntu 22.04 LTS Server |
| **R√©seau** | Connexion Gigabit au r√©seau interne |

**Proc√©dure de d√©ploiement on-premise :**

**√âtape 1 : Pr√©paration du serveur**

```bash
# Mise √† jour du syst√®me
sudo apt update && sudo apt upgrade -y

# Installation de Python 3.10
sudo apt install python3.10 python3.10-venv python3-pip -y

# Installation de Git
sudo apt install git -y

# Installation d'Ollama
curl -fsSL https://ollama.com/install.sh | sh

# T√©l√©chargement de Mistral 7B
ollama pull mistral
```

**√âtape 2 : D√©ploiement de l'application**

```bash
# Clonage du projet (ou transfert via SCP)
git clone https://github.com/entreprise/telecom-rag.git
cd telecom-rag

# Cr√©ation de l'environnement virtuel
python3.10 -m venv venv
source venv/bin/activate

# Installation des d√©pendances
pip install -r requirements.txt

# Configuration des variables d'environnement
cp .env.example .env
nano .env  # √âditer les param√®tres

# Indexation initiale des documents
python src/build_vectorstore.py

# Test du pipeline RAG
python src/test_rag.py
```

**√âtape 3 : Configuration de Streamlit comme service**

Pour que l'application d√©marre automatiquement au d√©marrage du serveur :

```bash
# Cr√©er un service systemd
sudo nano /etc/systemd/system/telecom-rag.service

# Contenu du fichier :
[Unit]
Description=Telecom RAG Streamlit App
After=network.target

[Service]
Type=simple
User=raguser
WorkingDirectory=/home/raguser/telecom-rag
Environment="PATH=/home/raguser/telecom-rag/venv/bin"
ExecStart=/home/raguser/telecom-rag/venv/bin/streamlit run app/streamlit_app.py --server.port=8501 --server.address=0.0.0.0
Restart=always

[Install]
WantedBy=multi-user.target

# Activer et d√©marrer le service
sudo systemctl enable telecom-rag
sudo systemctl start telecom-rag
sudo systemctl status telecom-rag
```

**√âtape 4 : Configuration du pare-feu**

```bash
# Autoriser le port Streamlit (8501) uniquement depuis le r√©seau interne
sudo ufw allow from 192.168.0.0/16 to any port 8501
sudo ufw enable
```

**√âtape 5 : Acc√®s depuis les postes clients**

Les utilisateurs acc√®dent √† l'application via leur navigateur :

```
http://serveur-rag.interne:8501
ou
http://192.168.1.100:8501
```

#### 2.5.2. D√©ploiement cloud hybride

**Contexte :**

Certaines entreprises de t√©l√©communication adoptent une strat√©gie cloud hybride :
- **Donn√©es sensibles** : Restent on-premise
- **Interface et logique m√©tier** : Peuvent √™tre h√©berg√©es sur un cloud priv√© ou public

**Architecture cloud hybride :**

```
Cloud (Azure/AWS/GCP)
‚îÇ
‚îú‚îÄ‚îÄ Interface Streamlit (conteneur Docker)
‚îÇ   ‚îî‚îÄ‚îÄ Accessible via HTTPS (SSL/TLS)
‚îÇ
‚îî‚îÄ‚îÄ API Gateway (s√©curis√©e)
    ‚Üì
    [Connexion VPN/VPC s√©curis√©e]
    ‚Üì
Serveur on-premise
‚îÇ
‚îú‚îÄ‚îÄ Ollama + Mistral 7B
‚îú‚îÄ‚îÄ Base vectorielle FAISS
‚îî‚îÄ‚îÄ Documents internes
```

**Avantages :**

‚úÖ **Accessibilit√©** : Acc√®s depuis n'importe o√π (mobile, t√©l√©travail)  
‚úÖ **Scalabilit√©** : L'interface peut g√©rer plus d'utilisateurs  
‚úÖ **S√©curit√© des donn√©es** : Les documents restent on-premise  
‚úÖ **Maintenance simplifi√©e** : Mises √† jour de l'interface facilit√©es  

**Contraintes :**

‚ö†Ô∏è **Complexit√©** : Architecture plus complexe √† mettre en place  
‚ö†Ô∏è **Latence** : L√©g√®re augmentation due aux appels r√©seau  
‚ö†Ô∏è **Co√ªts** : Co√ªts cloud pour l'h√©bergement de l'interface  

#### 2.5.3. S√©curit√© et confidentialit√©

**Mesures de s√©curit√© essentielles :**

**1. Authentification et contr√¥le d'acc√®s**

- **Authentification SSO** : Int√©gration avec Active Directory / LDAP de l'entreprise
- **R√¥les et permissions** :
  - Administrateur : Gestion des documents, configuration
  - Utilisateur commercial : Acc√®s aux offres et proc√©dures commerciales
  - Utilisateur support : Acc√®s aux proc√©dures techniques et FAQ
  - Utilisateur juridique : Acc√®s aux CGV, SLA, contrats

**2. Chiffrement**

- **En transit** : HTTPS/TLS pour toutes les communications
- **Au repos** : Chiffrement du disque contenant la base vectorielle et les documents

**3. Audit et tra√ßabilit√©**

- **Logs d'acc√®s** : Qui a pos√© quelle question, quand
- **Logs de modification** : Qui a ajout√©/supprim√© des documents
- **Alertes** : Notification en cas de tentative d'acc√®s non autoris√©

**4. Isolation r√©seau**

- **Segmentation** : Le serveur RAG est dans un VLAN d√©di√©
- **Pare-feu** : R√®gles strictes limitant les acc√®s entrants/sortants

**5. Sauvegarde et reprise d'activit√©**

- **Sauvegardes quotidiennes** : Base vectorielle + documents
- **Plan de reprise** : Proc√©dure de restauration en cas de panne
- **Serveur de secours** : Redondance pour la haute disponibilit√©

#### 2.5.4. Conformit√© r√©glementaire (RGPD, ARTP)

**RGPD (R√®glement G√©n√©ral sur la Protection des Donn√©es) :**

Si le syst√®me traite des donn√©es personnelles (ex : historique de questions contenant des noms de clients) :

- **Minimisation** : Ne collecter que les donn√©es n√©cessaires
- **Droit √† l'effacement** : Possibilit√© de supprimer l'historique d'un utilisateur
- **Transparence** : Informer les utilisateurs de l'utilisation de leurs donn√©es
- **S√©curit√©** : Mesures techniques et organisationnelles appropri√©es

**ARTP (Autorit√© de R√©gulation des T√©l√©communications et des Postes) :**

Respect des obligations r√©glementaires :
- **Confidentialit√© des communications** : Ne pas exposer de donn√©es clients
- **Archivage** : Conservation des documents r√©glementaires selon les dur√©es l√©gales

---

### 2.6. Mise en place d'une interface de test accessible √† distance (Streamlit)

L'interface utilisateur est le point de contact entre les employ√©s et le syst√®me RAG. Elle doit √™tre intuitive, rapide et professionnelle.

#### 2.6.1. Conception de l'interface Streamlit

**Fichier : `app/streamlit_app.py`**

**Fonctionnalit√©s de l'interface :**

**Page principale :**

1. **En-t√™te avec logo et titre**
   - Logo de l'entreprise (Orange, Expresso, YAS)
   - Titre : "Assistant Intelligent - Base de Connaissances T√©l√©com"

2. **Zone de saisie de question**
   - Champ de texte large et visible
   - Placeholder : "Posez votre question sur les offres, proc√©dures ou conditions..."
   - Bouton "Rechercher" avec ic√¥ne

3. **Affichage de la r√©ponse**
   - R√©ponse g√©n√©r√©e par le LLM (format√©e en markdown)
   - Temps de r√©ponse affich√©
   - Indicateur de confiance (optionnel)

4. **Affichage des sources**
   - Liste des documents utilis√©s
   - Liens vers les documents (si accessibles)
   - Extraits pertinents surlign√©s

5. **Barre lat√©rale (sidebar)**
   - Param√®tres de recherche :
     - Nombre de sources √† r√©cup√©rer (top-k)
     - Choix du mod√®le (Mistral local / API externe)
   - Statistiques :
     - Nombre de documents index√©s
     - Date de derni√®re mise √† jour
   - Historique des questions r√©centes

**Charte graphique (inspir√©e de YAS) :**

```python
# Couleurs YAS
PRIMARY_COLOR = "#6B2D8F"      # Violet YAS
SECONDARY_COLOR = "#00D9A3"    # Vert accent
BACKGROUND_COLOR = "#F5F5F5"   # Gris clair
TEXT_COLOR = "#2C2C2C"         # Gris fonc√©

# Configuration Streamlit
st.set_page_config(
    page_title="Assistant T√©l√©com RAG",
    page_icon="üì°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown(f"""
    <style>
    .main {{
        background-color: {BACKGROUND_COLOR};
    }}
    .stButton>button {{
        background-color: {PRIMARY_COLOR};
        color: white;
        border-radius: 8px;
        padding: 10px 24px;
        font-weight: bold;
    }}
    .stButton>button:hover {{
        background-color: {SECONDARY_COLOR};
    }}
    </style>
""", unsafe_allow_html=True)
```

#### 2.6.2. Exp√©rience utilisateur (UX)

**Parcours utilisateur type :**

1. **Arriv√©e sur la page**
   - Message de bienvenue
   - Exemples de questions sugg√©r√©es

2. **Saisie de la question**
   - Autocompl√©tion (optionnel)
   - Validation en temps r√©el (question non vide)

3. **Traitement**
   - Indicateur de chargement ("Recherche en cours...")
   - Animation (spinner)

4. **Affichage des r√©sultats**
   - R√©ponse claire et structur√©e
   - Sources cliquables
   - Bouton "Nouvelle question"

5. **Feedback utilisateur**
   - Boutons "üëç Utile" / "üëé Pas utile"
   - Zone de commentaire (optionnel)

**Optimisations UX :**

- **Temps de r√©ponse** : Afficher un message si la r√©ponse prend plus de 5 secondes
- **Gestion des erreurs** : Messages d'erreur clairs et actions correctives
- **Responsive design** : Adapt√© aux √©crans desktop et tablettes
- **Accessibilit√©** : Contraste suffisant, taille de police lisible

#### 2.6.3. Fonctionnalit√©s avanc√©es

**1. Historique conversationnel**

Permettre des √©changes multi-tours :

```
Utilisateur : "Quelles sont les offres entreprise ?"
Assistant : "Nous proposons 3 offres entreprise : Pro 50 Go, Pro 100 Go, Pro Illimit√©..."

Utilisateur : "Quel est le prix de la Pro 100 Go ?"
Assistant : "L'offre Pro 100 Go co√ªte 25 000 FCFA par mois..."
```

**2. Export des r√©ponses**

- Bouton "T√©l√©charger en PDF"
- Bouton "Copier dans le presse-papier"

**3. Recherche avanc√©e**

- Filtres par cat√©gorie (commercial, technique, juridique)
- Filtres par date de document

**4. Analytics pour les administrateurs**

- Questions les plus fr√©quentes
- Documents les plus consult√©s
- Taux de satisfaction des r√©ponses

#### 2.6.4. Acc√®s √† distance s√©curis√©

**Option 1 : VPN d'entreprise**

Les utilisateurs se connectent au VPN de l'entreprise, puis acc√®dent √† l'application via l'URL interne.

**Option 2 : Reverse proxy avec authentification**

Utilisation de Nginx comme reverse proxy avec authentification :

```nginx
server {
    listen 443 ssl;
    server_name rag.entreprise.sn;

    ssl_certificate /etc/ssl/certs/entreprise.crt;
    ssl_certificate_key /etc/ssl/private/entreprise.key;

    location / {
        proxy_pass http://localhost:8501;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;

        # Authentification basique
        auth_basic "Zone Restreinte";
        auth_basic_user_file /etc/nginx/.htpasswd;
    }
}
```

**Option 3 : Streamlit Cloud avec authentification**

D√©ploiement sur Streamlit Cloud avec authentification Google/Microsoft :

```python
import streamlit_authenticator as stauth

# Configuration de l'authentification
authenticator = stauth.Authenticate(
    credentials,
    'telecom_rag',
    'auth_key',
    cookie_expiry_days=30
)

name, authentication_status, username = authenticator.login('Login', 'main')

if authentication_status:
    # Afficher l'application
    st.write(f'Bienvenue {name}')
    # ... reste de l'application
elif authentication_status == False:
    st.error('Nom d\'utilisateur ou mot de passe incorrect')
```

---

### 2.7. Limites actuelles et pistes d'am√©lioration

Cette section identifie les limites du syst√®me MVP et propose des pistes d'√©volution pour les versions futures.

#### 2.7.1. Limites du syst√®me actuel

**Limites techniques :**

**1. Performance du mod√®le**
- **Limite** : Mistral 7B (Q4) a des capacit√©s limit√©es compar√© √† GPT-4 ou Claude
- **Impact** : R√©ponses parfois moins nuanc√©es, compr√©hension limit√©e de questions tr√®s complexes
- **Mitigation** : Utiliser une version moins quantifi√©e (Q5, Q8) si plus de RAM disponible

**2. Taille de la base documentaire**
- **Limite** : FAISS IndexFlatL2 devient lent au-del√† de 100k vecteurs
- **Impact** : Temps de recherche augmente avec le nombre de documents
- **Mitigation** : Utiliser un index FAISS optimis√© (IVF, HNSW) pour de grandes bases

**3. Absence de fine-tuning**
- **Limite** : Le mod√®le n'est pas sp√©cifiquement entra√Æn√© sur le vocabulaire t√©l√©com
- **Impact** : Peut ne pas reconna√Ætre certains acronymes ou termes techniques sp√©cifiques
- **Mitigation** : Ajouter un glossaire dans le prompt syst√®me

**4. Recherche s√©mantique basique**
- **Limite** : Recherche par similarit√© simple, sans r√©ranking
- **Impact** : Parfois, des chunks moins pertinents sont inclus dans le contexte
- **Mitigation** : Ajouter un mod√®le de r√©ranking (cross-encoder)

**Limites fonctionnelles :**

**1. Pas de mise √† jour en temps r√©el**
- **Limite** : La base vectorielle doit √™tre r√©index√©e manuellement
- **Impact** : D√©lai entre l'ajout d'un document et sa disponibilit√© dans le syst√®me
- **Mitigation** : Impl√©menter un syst√®me de surveillance de dossier avec r√©indexation automatique

**2. Pas de gestion multi-utilisateurs avanc√©e**
- **Limite** : Pas de sessions utilisateur distinctes, pas de personnalisation
- **Impact** : Tous les utilisateurs voient les m√™mes r√©sultats
- **Mitigation** : Ajouter un syst√®me d'authentification et de profils utilisateurs

**3. Pas de feedback loop**
- **Limite** : Le syst√®me ne s'am√©liore pas avec l'usage
- **Impact** : Les m√™mes erreurs peuvent se r√©p√©ter
- **Mitigation** : Collecter les feedbacks (üëç/üëé) et ajuster les prompts ou les documents

**4. Support monolingue (fran√ßais uniquement)**
- **Limite** : Pas de support pour le wolof, l'anglais ou d'autres langues
- **Impact** : Limite l'utilisation dans certains contextes
- **Mitigation** : Utiliser un mod√®le multilingue et traduire les documents

**Limites de s√©curit√© :**

**1. Pas d'audit d√©taill√©**
- **Limite** : Logs basiques, pas de tra√ßabilit√© fine
- **Impact** : Difficile de d√©tecter des usages abusifs
- **Mitigation** : Impl√©menter un syst√®me de logging avanc√©

**2. Pas de contr√¥le d'acc√®s granulaire**
- **Limite** : Tous les utilisateurs authentifi√©s ont acc√®s √† tous les documents
- **Impact** : Risque de fuite d'informations sensibles
- **Mitigation** : Impl√©menter un syst√®me de permissions par document/cat√©gorie

#### 2.7.2. Pistes d'am√©lioration √† court terme (3-6 mois)

**Am√©lioration 1 : Optimisation de la recherche**

- **Objectif** : Am√©liorer la pertinence des r√©sultats
- **Actions** :
  - Impl√©menter un mod√®le de r√©ranking (cross-encoder)
  - Tester diff√©rentes strat√©gies de chunking
  - Ajouter des filtres de m√©tadonn√©es (date, cat√©gorie)

**Am√©lioration 2 : Interface utilisateur enrichie**

- **Objectif** : Am√©liorer l'exp√©rience utilisateur
- **Actions** :
  - Ajouter l'historique conversationnel (chat multi-tours)
  - Impl√©menter l'export PDF des r√©ponses
  - Ajouter des suggestions de questions

**Am√©lioration 3 : Monitoring et analytics**

- **Objectif** : Suivre l'utilisation et la performance
- **Actions** :
  - Dashboard d'analytics (questions fr√©quentes, taux de satisfaction)
  - Alertes en cas de baisse de performance
  - Rapports d'utilisation hebdomadaires

**Am√©lioration 4 : Mise √† jour automatis√©e**

- **Objectif** : Faciliter la maintenance de la base documentaire
- **Actions** :
  - Script de surveillance d'un dossier partag√©
  - R√©indexation automatique lors de l'ajout de nouveaux fichiers
  - Notification des utilisateurs lors de mises √† jour majeures

#### 2.7.3. Pistes d'am√©lioration √† moyen terme (6-12 mois)

**Am√©lioration 1 : Fine-tuning du mod√®le**

- **Objectif** : Adapter le mod√®le au vocabulaire t√©l√©com
- **Actions** :
  - Collecter un corpus de questions-r√©ponses t√©l√©com
  - Fine-tuner Mistral 7B sur ce corpus
  - √âvaluer les gains de performance

**Am√©lioration 2 : Support multilingue**

- **Objectif** : Supporter le wolof, l'anglais et le fran√ßais
- **Actions** :
  - Traduire les documents cl√©s
  - Utiliser un mod√®le multilingue (mT5, BLOOM)
  - Tester la qualit√© des r√©ponses en wolof et anglais

**Am√©lioration 3 : Int√©gration avec les syst√®mes existants**

- **Objectif** : Connecter le RAG aux outils m√©tier
- **Actions** :
  - Int√©gration avec le CRM (Salesforce, Microsoft Dynamics)
  - Int√©gration avec le syst√®me de ticketing (Zendesk, Freshdesk)
  - API REST pour permettre l'utilisation par d'autres applications

**Am√©lioration 4 : Scalabilit√© et haute disponibilit√©**

- **Objectif** : Supporter des milliers d'utilisateurs simultan√©s
- **Actions** :
  - Migration vers une base vectorielle distribu√©e (Milvus, Weaviate)
  - D√©ploiement en cluster (Kubernetes)
  - Load balancing et r√©plication

#### 2.7.4. Pistes d'am√©lioration √† long terme (12+ mois)

**Am√©lioration 1 : Agent conversationnel avanc√©**

- **Objectif** : Transformer le syst√®me en v√©ritable assistant conversationnel
- **Actions** :
  - Ajout de la compr√©hension du contexte multi-tours
  - Capacit√© √† effectuer des actions (cr√©er un ticket, envoyer un email)
  - Int√©gration vocale (speech-to-text, text-to-speech)

**Am√©lioration 2 : Apprentissage continu**

- **Objectif** : Le syst√®me s'am√©liore automatiquement avec l'usage
- **Actions** :
  - Collecte des feedbacks utilisateurs
  - R√©entra√Ænement p√©riodique du mod√®le
  - Ajustement automatique des prompts

**Am√©lioration 3 : Analyse pr√©dictive**

- **Objectif** : Anticiper les besoins des utilisateurs
- **Actions** :
  - Analyse des tendances de questions
  - Identification proactive des lacunes documentaires
  - Recommandations de formation pour les √©quipes

**Am√©lioration 4 : Extension √† d'autres cas d'usage**

- **Objectif** : G√©n√©raliser le syst√®me √† d'autres d√©partements
- **Actions** :
  - RAG pour les RH (politiques internes, proc√©dures RH)
  - RAG pour la finance (proc√©dures comptables, r√©glementations)
  - RAG pour le marketing (guidelines de marque, strat√©gies)

---

## üéØ FIN DE LA PARTIE 2

**La PARTIE 2 est maintenant termin√©e.**

Cette deuxi√®me partie a permis de :
- ‚úÖ D√©tailler la mise en place de l'environnement de travail (Python, d√©pendances, structure)
- ‚úÖ Expliquer l'installation et la configuration d'Ollama et Mistral 7B
- ‚úÖ D√©crire la constitution d'une base de connaissances t√©l√©com repr√©sentative
- ‚úÖ Impl√©menter un pipeline RAG complet avec LangChain (ingestion, vectorisation, recherche, g√©n√©ration)
- ‚úÖ Aborder les strat√©gies d'h√©bergement (on-premise, cloud hybride) avec focus sur la s√©curit√©
- ‚úÖ Concevoir une interface Streamlit professionnelle et accessible √† distance
- ‚úÖ Identifier les limites actuelles et proposer des pistes d'am√©lioration r√©alistes

---

## üìä SYNTH√àSE DU PROJET COMPLET

### Ce qui a √©t√© accompli

**PARTIE 1 ‚Äì Cadrage**
- Analyse du contexte t√©l√©com et identification de la probl√©matique
- D√©finition d'objectifs fonctionnels, techniques et p√©dagogiques clairs
- Justification des choix technologiques (RAG, LangChain, Ollama, Mistral 7B)
- Description de l'architecture conceptuelle globale

**PARTIE 2 ‚Äì Mise en ≈ìuvre**
- Configuration compl√®te de l'environnement de d√©veloppement
- Installation et optimisation d'Ollama avec Mistral 7B (4 Go RAM)
- Constitution d'une base documentaire t√©l√©com structur√©e
- Impl√©mentation d'un pipeline RAG op√©rationnel
- Strat√©gies de d√©ploiement s√©curis√©es (on-premise privil√©gi√©)
- Interface utilisateur professionnelle avec charte YAS
- Identification des limites et roadmap d'√©volution

### Points forts du projet

‚úÖ **Alignement avec le cours** : RAG, LangChain, Ollama, Mistral parfaitement ma√Ætris√©s  
‚úÖ **Compr√©hension infrastructure** : On-premise vs cloud clairement expliqu√©  
‚úÖ **R√©alisme technique** : MVP r√©alisable, pas de sur-engagement  
‚úÖ **Contexte m√©tier** : Langage et probl√©matiques t√©l√©com authentiques  
‚úÖ **S√©curit√© et confidentialit√©** : Priorit√© donn√©e √† la protection des donn√©es  
‚úÖ **√âvolutivit√©** : Roadmap claire pour les √©volutions futures  

### Livrables du projet

üìÑ **Documentation compl√®te** : README.md acad√©mique et professionnel  
üèóÔ∏è **Architecture d√©taill√©e** : Composants, flux, d√©ploiement  
üîß **Sp√©cifications techniques** : Environnement, d√©pendances, configuration  
üé® **Design d'interface** : Charte graphique YAS, UX optimis√©e  
üìà **Roadmap d'√©volution** : Court, moyen et long terme  

---

## üé® RAPPEL : Charte graphique YAS

**Couleurs principales :**
- **Violet YAS** : `#6B2D8F` (innovation, modernit√©)
- **Vert accent** : `#00D9A3` (succ√®s, validation)
- **Blanc** : `#FFFFFF` (clart√©)
- **Gris fonc√©** : `#2C2C2C` (texte)

**Application dans l'interface :**
- Boutons principaux : Violet YAS
- Boutons de validation : Vert accent
- Fond : Blanc/Gris clair
- Texte : Gris fonc√©

---

**üìÖ Document r√©dig√© dans le cadre d'un projet acad√©mique**  
**üéì Intelligence Artificielle Appliqu√©e ‚Äì RAG et LLM**  
**üè¢ Cas d'usage : Entreprise de t√©l√©communication (S√©n√©gal)**  
**üë®‚Äçüè´ Align√© avec le cours : Ollama, LangChain, Mistral, RAG, Infrastructure**

---

**‚úÖ PROJET COMPLET ‚Äì PARTIES 1 & 2 TERMIN√âES**

Le document est maintenant complet et pr√™t pour pr√©sentation, √©valuation ou impl√©mentation technique.
